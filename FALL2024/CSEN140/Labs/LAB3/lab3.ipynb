{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Lab 3 Austin Nguyen***\n",
    "\n",
    "Friday, October 11, 2024 2:15- 5:00PM \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " LDA Feature Importance\n",
      "\n",
      "Accuracy with all features:\n",
      "Training accuracy: 97.50%\n",
      "Test accuracy: 100.00%\n",
      "\n",
      "Accuracy without Sepal Length:\n",
      "Training accuracy: 98.33%\n",
      "Test accuracy: 100.00%\n",
      "\n",
      "Accuracy without Sepal Width:\n",
      "Training accuracy: 97.50%\n",
      "Test accuracy: 100.00%\n",
      "\n",
      "Accuracy without Petal Length:\n",
      "Training accuracy: 94.17%\n",
      "Test accuracy: 100.00%\n",
      "\n",
      "Accuracy without Petal Width:\n",
      "Training accuracy: 95.83%\n",
      "Test accuracy: 96.67%\n",
      "\n",
      "QDA Training Accuracy: 98.33%\n",
      "QDA Test Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import (\n",
    "    LinearDiscriminantAnalysis,\n",
    "    QuadraticDiscriminantAnalysis,\n",
    ")\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset from given file\n",
    "def load_csv(filename):\n",
    "    data = []\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                split_line = line.split(',')\n",
    "                features = list(map(float, split_line[:4])) # Convert first 4 columns to float\n",
    "                label = split_line[4]  # Class label as a string\n",
    "                data.append(features + [label])\n",
    "    return data\n",
    "\n",
    "# Test the data format using the given function\n",
    "def test_dataset(data):\n",
    "    if len(data) != 150:\n",
    "        return False\n",
    "    \n",
    "    for row in data:\n",
    "        if len(row) != 5:\n",
    "            return False\n",
    "        \n",
    "        for column in row[:-1]:\n",
    "            if type(column) != np.float64:\n",
    "                return False\n",
    "            \n",
    "        if type(row[-1]) != str:\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Split dataset into training and testing sets (80% training, 20% test)\n",
    "def split_data(data):\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    \n",
    "    # Split per class\n",
    "    classes = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
    "    for class_label in classes:\n",
    "        class_data = [row for row in data if row[-1] == class_label]\n",
    "        train_data += class_data[:40]  # First 40 instances for training\n",
    "        test_data += class_data[40:]  # Remaining 10 for testing\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "# Separate features and labels\n",
    "def separate_features_labels(dataset):\n",
    "    features = np.array([row[:-1] for row in dataset], dtype=np.float64)\n",
    "    labels = np.array([row[-1] for row in dataset])\n",
    "    return features, labels\n",
    "\n",
    "# Step 2: Linear Discriminant Analysis (LDA)\n",
    "def train_lda(train_features, train_labels):\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    lda.fit(train_features.astype(np.float64), train_labels)\n",
    "    return lda\n",
    "\n",
    "# Step 3: Quadratic Discriminant Analysis (QDA)\n",
    "def train_qda(train_features, train_labels):\n",
    "    qda = QuadraticDiscriminantAnalysis()\n",
    "    qda.fit(train_features.astype(np.float64), train_labels)\n",
    "    return qda\n",
    "\n",
    "# Function to calculate accuracy when missing one feature\n",
    "def featureaccuracy(model, train_features, train_labels, test_features, test_labels):\n",
    "    feature_names = [\"Sepal Length\", \"Sepal Width\", \"Petal Length\", \"Petal Width\"]\n",
    "    full_train_accuracy = accuracy_score(train_labels, model.predict(train_features))\n",
    "    full_test_accuracy = accuracy_score(test_labels, model.predict(test_features))\n",
    "\n",
    "    print(\"\\nAccuracy with all features:\")\n",
    "    print(f\"Training accuracy: {full_train_accuracy * 100:.2f}%\")\n",
    "    print(f\"Test accuracy: {full_test_accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Iterate over each feature and remove it\n",
    "    for i in range(train_features.shape[1]):\n",
    "        # Remove feature i from the dataset\n",
    "        reduced_train_features = np.delete(train_features, i, axis=1)\n",
    "        reduced_test_features = np.delete(test_features, i, axis=1)\n",
    "\n",
    "        # Retrain the model with the reduced dataset\n",
    "        model.fit(reduced_train_features, train_labels)\n",
    "\n",
    "        # Calculate accuracy with the reduced feature set\n",
    "        reduced_train_accuracy = accuracy_score(train_labels, model.predict(reduced_train_features))\n",
    "        reduced_test_accuracy = accuracy_score(test_labels, model.predict(reduced_test_features))\n",
    "\n",
    "        # Print the results for the feature removed\n",
    "        print(f\"\\nAccuracy without {feature_names[i]}:\")\n",
    "        print(f\"Training accuracy: {reduced_train_accuracy * 100:.2f}%\")\n",
    "        print(f\"Test accuracy: {reduced_test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Main workflow\n",
    "if __name__ == \"__main__\":\n",
    "    filename = 'iris.data.csv'  \n",
    "    data = load_csv(filename)\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    train_data, test_data = split_data(data)\n",
    "\n",
    "    # Separate features and labels for training and testing sets\n",
    "    train_features, train_labels = separate_features_labels(train_data)\n",
    "    test_features, test_labels = separate_features_labels(test_data)\n",
    "\n",
    "    # Train and evaluate LDA model\n",
    "    lda_classifier = train_lda(train_features, train_labels)\n",
    "\n",
    "    # Feature importance using leave-one-out accuracy for LDA\n",
    "    print(\"\\n LDA Feature Importance\")\n",
    "    featureaccuracy(lda_classifier, train_features, train_labels, test_features, test_labels)\n",
    "\n",
    "    # QDA model\n",
    "    qda_classifier = train_qda(train_features, train_labels)\n",
    "    \n",
    "    train_predictions_qda = qda_classifier.predict(train_features)\n",
    "    test_predictions_qda = qda_classifier.predict(test_features)\n",
    "\n",
    "    train_accuracy_qda = accuracy_score(train_labels, train_predictions_qda)\n",
    "    test_accuracy_qda = accuracy_score(test_labels, test_predictions_qda)\n",
    "\n",
    "    print(f\"\\nQDA Training Accuracy: {train_accuracy_qda * 100:.2f}%\")\n",
    "    print(f\"QDA Test Accuracy: {test_accuracy_qda * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Part 4 Feature Importance Analysis***\n",
    "\n",
    "\n",
    "When testing one at a time, Petal Length and Petal Width affected the accuracies of the tests while sepal length/width did not (accuracies went down)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
