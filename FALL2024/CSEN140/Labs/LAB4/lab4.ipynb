{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 4 Austin Nguyen\n",
    "\n",
    "October 18, 2024: Friday 2:15 - 5:00 PM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Training Accuracy: 97.50%\n",
      "LDA Test Accuracy: 100.00%\n",
      "QDA Training Accuracy: 98.33%\n",
      "QDA Test Accuracy: 100.00%\n",
      "Original QDA Training Time: 0.0065 seconds\n",
      "Diagonal QDA Training Accuracy: 95.83%\n",
      "Diagonal QDA Test Accuracy: 100.00%\n",
      "Diagonal QDA Training Time: 0.0048 seconds\n",
      "\n",
      "Binary Classification: Iris-setosa vs Rest\n",
      "Iris-setosa Training Accuracy: 100.00%\n",
      "Iris-setosa Test Accuracy: 100.00%\n",
      "\n",
      "Binary Classification: Iris-versicolor vs Rest\n",
      "Iris-versicolor Training Accuracy: 73.33%\n",
      "Iris-versicolor Test Accuracy: 76.67%\n",
      "\n",
      "Binary Classification: Iris-virginica vs Rest\n",
      "Iris-virginica Training Accuracy: 90.83%\n",
      "Iris-virginica Test Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Load the dataset from given file\n",
    "def load_csv(filename):\n",
    "    data = []\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                split_line = line.split(',')\n",
    "                features = list(map(float, split_line[:4]))  # Convert first 4 columns to float\n",
    "                label = split_line[4]  # Class label as a string\n",
    "                data.append(features + [label])\n",
    "    return data\n",
    "\n",
    "# Split dataset into training and testing sets (80% training, 20% test)\n",
    "def split_data(data):\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    \n",
    "    # Split per class\n",
    "    classes = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
    "    for class_label in classes:\n",
    "        class_data = [row for row in data if row[-1] == class_label]\n",
    "        train_data += class_data[:40]  # First 40 instances for training\n",
    "        test_data += class_data[40:]  # Remaining 10 for testing\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "# Separate features and labels\n",
    "def separate_features_labels(dataset):\n",
    "    features = np.array([row[:-1] for row in dataset], dtype=np.float64)\n",
    "    labels = np.array([row[-1] for row in dataset])\n",
    "    return features, labels\n",
    "\n",
    "# Mean and covariance per class\n",
    "def compute_class_stats(features, labels):\n",
    "    class_stats = {}\n",
    "    for class_label in np.unique(labels):\n",
    "        class_features = features[labels == class_label]\n",
    "        mean = np.mean(class_features, axis=0)\n",
    "        cov = np.cov(class_features, rowvar=False)\n",
    "        class_stats[class_label] = {\"mean\": mean, \"cov\": cov}\n",
    "    return class_stats\n",
    "\n",
    "# Shared covariance matrix for LDA\n",
    "def compute_shared_cov(features, labels, class_stats):\n",
    "    n_samples = len(features)\n",
    "    shared_cov = np.zeros((features.shape[1], features.shape[1]))\n",
    "    \n",
    "    for class_label in np.unique(labels):\n",
    "        class_cov = class_stats[class_label][\"cov\"]\n",
    "        n_class_samples = len(features[labels == class_label])\n",
    "        shared_cov += (n_class_samples / n_samples) * class_cov  # Weighted sum\n",
    "    \n",
    "    return shared_cov\n",
    "\n",
    "# Binary classification: 1 for the class of interest, 0 for the other 2\n",
    "def binary_classification(train_labels, test_labels, target_class):\n",
    "    binary_train_labels = np.where(train_labels == target_class, 1, 0)  # Label 1 for target, 0 for others\n",
    "    binary_test_labels = np.where(test_labels == target_class, 1, 0)    # Label 1 for target, 0 for others\n",
    "    return binary_train_labels, binary_test_labels\n",
    "\n",
    "# LDA classifier implementation\n",
    "class LDA:\n",
    "    def __init__(self):\n",
    "        self.class_stats = None\n",
    "        self.priors = None\n",
    "        self.shared_cov = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.class_stats = compute_class_stats(X, y)\n",
    "        unique_classes, class_counts = np.unique(y, return_counts=True)\n",
    "        self.priors = class_counts / len(y)\n",
    "        self.shared_cov = compute_shared_cov(X, y, self.class_stats)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        cov_inv = np.linalg.inv(self.shared_cov)\n",
    "        \n",
    "        for x in X:\n",
    "            class_probs = []\n",
    "            for idx, class_label in enumerate(self.class_stats.keys()):\n",
    "                mean = self.class_stats[class_label][\"mean\"]\n",
    "                prior = self.priors[idx]\n",
    "\n",
    "                # Compute the LDA discriminant function using the shared covariance matrix\n",
    "                discriminant = np.dot(np.dot(x, cov_inv), mean) - 0.5 * np.dot(np.dot(mean.T, cov_inv), mean) + np.log(prior)\n",
    "                class_probs.append(discriminant)\n",
    "                \n",
    "            predictions.append(list(self.class_stats.keys())[np.argmax(class_probs)])\n",
    "        return np.array(predictions)\n",
    "\n",
    "# QDA classifier implementation (same from lab 3)\n",
    "class QDA:\n",
    "    def __init__(self):\n",
    "        self.class_stats = None\n",
    "        self.priors = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.class_stats = compute_class_stats(X, y)\n",
    "        unique_classes, class_counts = np.unique(y, return_counts=True)\n",
    "        self.priors = class_counts / len(y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            class_probs = []\n",
    "            for idx, class_label in enumerate(self.class_stats.keys()):\n",
    "                mean = self.class_stats[class_label][\"mean\"]\n",
    "                cov = self.class_stats[class_label][\"cov\"]\n",
    "                cov_inv = np.linalg.inv(cov)\n",
    "                prior = self.priors[idx]\n",
    "                \n",
    "                # Compute the QDA discriminant function\n",
    "                discriminant = -0.5 * np.dot(np.dot((x - mean).T, cov_inv), (x - mean)) \\\n",
    "                               - 0.5 * np.log(np.linalg.det(cov)) + np.log(prior)\n",
    "                class_probs.append(discriminant)\n",
    "            predictions.append(list(self.class_stats.keys())[np.argmax(class_probs)])\n",
    "        return np.array(predictions)\n",
    "\n",
    "\n",
    "# Modified QDA to assume diagonal covariance matrix\n",
    "class DiagonalQDA:\n",
    "    def __init__(self):\n",
    "        self.class_stats = None\n",
    "        self.priors = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.class_stats = compute_class_stats(X, y)\n",
    "        unique_classes, class_counts = np.unique(y, return_counts=True)\n",
    "        self.priors = class_counts / len(y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            class_probs = []\n",
    "            for idx, class_label in enumerate(self.class_stats.keys()):\n",
    "                mean = self.class_stats[class_label][\"mean\"]\n",
    "                cov = self.class_stats[class_label][\"cov\"]\n",
    "                \n",
    "                # Assume diagonal covariance matrix: Use only the diagonal elements (variances)\n",
    "                diagonal_cov_inv = np.diag(1 / np.diag(cov))\n",
    "                prior = self.priors[idx]\n",
    "\n",
    "                # Compute the QDA discriminant function with diagonal covariance\n",
    "                discriminant = -0.5 * np.dot(np.dot((x - mean).T, diagonal_cov_inv), (x - mean)) \\\n",
    "                               - 0.5 * np.sum(np.log(np.diag(cov))) + np.log(prior)\n",
    "                class_probs.append(discriminant)\n",
    "            predictions.append(list(self.class_stats.keys())[np.argmax(class_probs)])\n",
    "        return np.array(predictions)\n",
    "    \n",
    "# Calculate accuracy\n",
    "def accuracy(predictions, labels):\n",
    "    return np.mean(predictions == labels) * 100\n",
    "\n",
    "# Main workflow\n",
    "if __name__ == \"__main__\":\n",
    "    filename = 'iris.data.csv'\n",
    "    data = load_csv(filename)\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    train_data, test_data = split_data(data)\n",
    "\n",
    "    # Separate features and labels for training and testing sets\n",
    "    train_features, train_labels = separate_features_labels(train_data)\n",
    "    test_features, test_labels = separate_features_labels(test_data)\n",
    "\n",
    "    # LDA\n",
    "    lda = LDA()\n",
    "    lda.fit(train_features, train_labels)\n",
    "    train_predictions_lda = lda.predict(train_features)\n",
    "    test_predictions_lda = lda.predict(test_features)\n",
    "\n",
    "    print(f\"LDA Training Accuracy: {accuracy(train_predictions_lda, train_labels):.2f}%\")\n",
    "    print(f\"LDA Test Accuracy: {accuracy(test_predictions_lda, test_labels):.2f}%\")\n",
    "\n",
    "    # Original QDA\n",
    "    qda = QDA()\n",
    "    start_time_qda = time.time()\n",
    "    qda.fit(train_features, train_labels)\n",
    "    train_predictions_qda = qda.predict(train_features)\n",
    "    test_predictions_qda = qda.predict(test_features)\n",
    "    end_time_qda = time.time()\n",
    "\n",
    "    print(f\"QDA Training Accuracy: {accuracy(train_predictions_qda, train_labels):.2f}%\")\n",
    "    print(f\"QDA Test Accuracy: {accuracy(test_predictions_qda, test_labels):.2f}%\")\n",
    "    print(f\"Original QDA Training Time: {end_time_qda - start_time_qda:.4f} seconds\")\n",
    "\n",
    "    # Diagonal QDA\n",
    "    diagonal_qda = DiagonalQDA()\n",
    "    start_time_diag_qda = time.time()\n",
    "    diagonal_qda.fit(train_features, train_labels)\n",
    "    train_predictions_diag_qda = diagonal_qda.predict(train_features)\n",
    "    test_predictions_diag_qda = diagonal_qda.predict(test_features)\n",
    "    end_time_diag_qda = time.time()\n",
    "\n",
    "    print(f\"Diagonal QDA Training Accuracy: {accuracy(train_predictions_diag_qda, train_labels):.2f}%\")\n",
    "    print(f\"Diagonal QDA Test Accuracy: {accuracy(test_predictions_diag_qda, test_labels):.2f}%\")\n",
    "    print(f\"Diagonal QDA Training Time: {end_time_diag_qda - start_time_diag_qda:.4f} seconds\")\n",
    "\n",
    "\n",
    "    classes = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
    "\n",
    "    for target_class in classes:\n",
    "        print(f\"\\nBinary Classification: {target_class} vs Rest\")\n",
    "        \n",
    "        # Prepare binary labels for classification\n",
    "        binary_train_labels, binary_test_labels = binary_classification(train_labels, test_labels, target_class)\n",
    "\n",
    "        # Train LDA model\n",
    "        lda = LDA()\n",
    "        lda.fit(train_features, binary_train_labels)\n",
    "\n",
    "        # Make predictions\n",
    "        train_predictions = lda.predict(train_features)\n",
    "        test_predictions = lda.predict(test_features)\n",
    "\n",
    "        # Calculate and print accuracies\n",
    "        train_accuracy = accuracy(train_predictions, binary_train_labels)\n",
    "        test_accuracy = accuracy(test_predictions, binary_test_labels)\n",
    "\n",
    "        print(f\"{target_class} Training Accuracy: {train_accuracy:.2f}%\")\n",
    "        print(f\"{target_class} Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "# # Binary classification: 1 for the class of interest, 0 for the other 2\n",
    "# def binary_classification(train_labels, test_labels, target_class):\n",
    "#     binary_train_labels = np.where(train_labels == target_class, 1, 0)  # Label 1 for target, 0 for others\n",
    "#     binary_test_labels = np.where(test_labels == target_class, 1, 0)    # Label 1 for target, 0 for others\n",
    "#     return binary_train_labels, binary_test_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Part 4 Conclusions for Binary Classification:***\n",
    "\n",
    "Iris-setosa had 100% accuracy for both the testing and training, which implies that there is a defined line that can be drawn between this class of data and the other 2. The accuracies of the other 2 classes, Versicolor and Virginica, support the claim, since their percentages are smaller, it was harder to draw defined lines between the data sets of each. \n",
    "\n",
    "***Part 5 Runtime with Diagonal Cov Matrix:***\n",
    "\n",
    "The runtime of the QDA with the diagonal matrix was smaller because we are only concerned with 4/16 of the possible elements of the matrix compared to all 16 elements of the 4 x 4 matrix of the original QDA\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
