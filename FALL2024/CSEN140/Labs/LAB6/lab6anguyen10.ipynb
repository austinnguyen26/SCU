{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6 Austin Nguyen\n",
    "\n",
    "November 8, 2024\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best lambda: 25.0\n",
      "Problem 1 Training RMSE: 0.1287970145987978\n",
      "Problem 1 Testing RMSE: 0.1457465070705802\n",
      "Problem 2 Training RMSE: 0.12828429481592424\n",
      "Problem 2 Testing RMSE: 0.14568341221467915\n",
      "25.0\n",
      "25.0\n",
      "Problem 3 Training RMSE: 0.12877146243488172\n",
      "Problem 3 Testing RMSE: 0.14562337951330204\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import csv \n",
    "\n",
    "def load_data(name):\n",
    "    data = []\n",
    "    with open(name, mode = 'r') as file:\n",
    "        csvFile = csv.reader(file, delimiter='\\t')\n",
    "        next(csvFile) #skip the first line\n",
    "        for lines in csvFile:\n",
    "            converted_lines = []\n",
    "            for x in lines:\n",
    "                converted_lines.append(float(x))\n",
    "            data.append(converted_lines)\n",
    "    return data\n",
    "\n",
    "k_fold = 5\n",
    "\n",
    "train_data = np.array(load_data('crime-train.csv'))\n",
    "y_train = train_data[:, 0]\n",
    "x_train = train_data[:, 1:]\n",
    "\n",
    "\n",
    "# adding the dummy feature\n",
    "x = np.ones((x_train.shape[0], 1))\n",
    "x_train = np.append(x_train, x, 1)\n",
    "\n",
    "\n",
    "\n",
    "test_data = np.array(load_data('crime-test.csv'))\n",
    "y_test = test_data[:, 0]\n",
    "x_test = test_data[:, 1:]\n",
    "\n",
    "x = np.ones((x_test.shape[0], 1))\n",
    "x_test = np.append(x_test, x, 1)\n",
    "\n",
    "# Splitting data\n",
    "\n",
    "split = int(x_train.shape[0]/k_fold)\n",
    "x_train1 = x_train[:split]\n",
    "x_train2 = x_train[split:split*2]\n",
    "x_train3 = x_train[split*2:split*3]\n",
    "x_train4 = x_train[split*3:split*4]\n",
    "x_train5 = x_train[split*4:]\n",
    "\n",
    "y_train1 = y_train[:split]\n",
    "y_train2 = y_train[split:split*2]\n",
    "y_train3 = y_train[split*2:split*3]\n",
    "y_train4 = y_train[split*3:split*4]\n",
    "y_train5 = y_train[split*4:]\n",
    "\n",
    "x_trainers = np.array([x_train1, x_train2, x_train3, x_train4, x_train5])\n",
    "y_trainers = np.array([y_train1, y_train2, y_train3, y_train4, y_train5])\n",
    "\n",
    "\n",
    "lambdas = np.zeros(10)\n",
    "lambdas[0] = 400\n",
    "for i in range(9):\n",
    "    lambdas[i+1] = lambdas[i]/2\n",
    "rmses = np.zeros(10)\n",
    "\n",
    "def rmse(x_estimated, x_actual):\n",
    "    n = x_estimated.shape[0]\n",
    "    sum = 0\n",
    "    for i in range(len(x_estimated)):\n",
    "        sum += np.power((x_actual[i]-x_estimated[i]), 2)\n",
    "    sum /= n\n",
    "    sum = np.power(sum, 1/2)\n",
    "    \n",
    "    return sum\n",
    "\n",
    "def ridge_fit(x_train, y_train, lam):\n",
    "\n",
    "    weights = np.dot(np.dot(np.linalg.inv(np.dot(x_train.T, x_train) + np.dot(lam, np.identity(x_train.shape[1]))), x_train.T), y_train)\n",
    "    return weights\n",
    "\n",
    "def prediction(x_test, weights):\n",
    "    \n",
    "    pred = []\n",
    "    pred = np.dot(x_test, weights)\n",
    "\n",
    "    return pred\n",
    "\n",
    "def create_nonval(trainers, i):\n",
    "    actual_train = []\n",
    "    for j in range(1, k_fold):\n",
    "        actual_train = np.append(actual_train, trainers[(i+j)%k_fold])\n",
    "    if (actual_train.shape[0] > 1276):\n",
    "        actual_train = np.reshape(actual_train, (1276, 96))\n",
    "    return actual_train\n",
    "\n",
    "def ridge_gradient_descent(x_train, y_train, lam):\n",
    "\n",
    "    tol = 0.0000001\n",
    "    diff = 1\n",
    "\n",
    "    w_t = np.random.rand(x_train.shape[1])\n",
    "    alpha = .00005\n",
    "\n",
    "    while (diff > tol):\n",
    "        temp_gradient = np.dot(lam, np.identity(x_train.shape[1]))\n",
    "        temp_gradient = np.dot(temp_gradient, w_t)\n",
    "\n",
    "        w_t1 = w_t - alpha * np.add(np.dot(x_train.T, np.subtract(np.dot(x_train, w_t), y_train)), temp_gradient)\n",
    "        diff = np.abs(np.average(w_t1-w_t))\n",
    "        w_t = w_t1\n",
    "        \n",
    "    return w_t\n",
    "\n",
    "\n",
    "def cross_validation():\n",
    "    for i in range(10):\n",
    "        avg_rmse = 0\n",
    "        # Make sure each fold is tested \n",
    "        for j in range(k_fold):\n",
    "\n",
    "            weight = ridge_gradient_descent(create_nonval(x_trainers, j), create_nonval(y_trainers, j), lambdas[i])\n",
    "\n",
    "            y_val = np.array(prediction(x_trainers[j], weight))\n",
    "            avg_rmse += rmse(y_val, y_trainers[j])\n",
    "\n",
    "        # average rmse for the current lambda\n",
    "        rmses[i]= avg_rmse/k_fold \n",
    "    \n",
    "    # chooses and returns the lambda with the lowest rmse\n",
    "    actual_lam = lambdas[np.argmin(rmses)]\n",
    "    return actual_lam\n",
    "\n",
    "# Step 1: uses cross validation to obtain the best lambda and then uses that to train\n",
    "actual_lam = cross_validation()\n",
    "\n",
    "print(f\"Best lambda: {actual_lam}\")\n",
    "\n",
    "weight = ridge_fit(x_train, y_train, actual_lam)\n",
    "train_pred = prediction(x_train, weight)\n",
    "rmse_train = rmse(train_pred, y_train)\n",
    "\n",
    "\n",
    "test_pred = prediction(x_test, weight)\n",
    "rmse_test = rmse(test_pred, y_test)\n",
    "\n",
    "print(f\"Problem 1 Training RMSE: {rmse_train}\")\n",
    "print(f\"Problem 1 Testing RMSE: {rmse_test}\")\n",
    "\n",
    "\n",
    "# Step 2: Linear Regression using Gradient Descent\n",
    "def problem2(samples):\n",
    "\n",
    "    tol = 0.0000001\n",
    "    diff = 1\n",
    "\n",
    "    w_t = np.random.rand(x_train.shape[1])\n",
    "\n",
    "    alpha = .00005\n",
    "\n",
    "    while (diff > tol):\n",
    "        w_t1 = w_t - alpha * np.dot(x_train.T,np.subtract(np.dot(x_train, w_t),y_train))\n",
    "\n",
    "        diff = np.abs(np.average(w_t1-w_t))\n",
    "        w_t = w_t1\n",
    "    \n",
    "    pred = np.dot(samples, w_t)\n",
    "    \n",
    "    return pred\n",
    "    \n",
    "\n",
    "train_pred = problem2(x_train)\n",
    "test_pred = problem2(x_test)\n",
    "\n",
    "print(f\"Problem 2 Training RMSE: {rmse(train_pred, y_train)}\")\n",
    "print(f\"Problem 2 Testing RMSE: {rmse(test_pred, y_test)}\")\n",
    "\n",
    "\n",
    "\n",
    "# Part 3: Ridge Regression with 5 Fold Cross Validation using Gradient Descent\n",
    "def problem3(samples):\n",
    "    actual_lam = cross_validation()\n",
    "    print(actual_lam)\n",
    "    weight = ridge_gradient_descent(x_train, y_train, actual_lam)\n",
    "    return prediction(samples,weight)\n",
    "\n",
    "\n",
    "train_pred = problem3(x_train)\n",
    "rmse_train = rmse(train_pred, y_train)\n",
    "\n",
    "test_pred = problem3(x_test)\n",
    "rmse_test = rmse(test_pred, y_test)\n",
    "\n",
    "print(f\"Problem 3 Training RMSE: {rmse_train}\")\n",
    "print(f\"Problem 3 Testing RMSE: {rmse_test}\")\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
